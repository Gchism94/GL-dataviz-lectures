{
  "hash": "e9a0af3dcb8ce5ed0877a74b0519144f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Time Series Visualizations\nsubtitle: INFO Data Visualization and Analysis - Week 4\ninstitute: UArizona School of Information\nauthor: Dr. Greg Chism\ntitle-slide-attributes:\n  data-background-image: minedata-bg.png\n  data-background-size: '600px, cover'\n  data-slide-number: none\nformat:\n  revealjs:\n    theme: slides.scss\n    transition: fade\n    slide-number: true\n    chalkboard: true\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\nauto-stretch: false\nfooter: \"[\\U0001F517 GL-dataviz-lectures](https://gchism94.github.io/GL-dataviz-lectures)\"\n---\n\n# Time Series Visualizations\n\n## Setup {.smaller}\n\n::: {#setup .cell message='false' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.dates import DateFormatter\nimport matplotlib.dates as mdates\nfrom skimpy import clean_columns\n\n# Set the theme for seaborn\nsns.set_theme(style=\"white\", palette=\"colorblind\")\n\n# Set figure parameters\nplt.rcParams['figure.figsize'] = [8, 8 * 0.618]\nplt.rcParams['figure.autolayout'] = True\n```\n:::\n\n\n# Working with dates\n\n## Air Quality Index\n\n-   The AQI is the Environmental Protection Agency's index for reporting air quality\n\n-   Higher values of AQI indicate worse air quality\n\n![](images/aqi-levels.png){fig-align=\"center\"}\n\n::: aside\nSource: <https://www.airnow.gov/aqi/aqi-basics/>\n:::\n\n## AQI levels\n\nThe previous graphic in tabular form, to be used later...\n\n::: {#d416dac2 .cell execution_count=2}\n``` {.python .cell-code}\naqi_levels = pd.DataFrame({\n    'aqi_min': [0, 51, 101, 151, 201, 301],\n    'aqi_max': [50, 100, 150, 200, 300, 400],\n    'color': [\"#D8EEDA\", \"#F1E7D4\", \"#F8E4D8\", \"#FEE2E1\", \"#F4E3F7\", \"#F9D0D4\"],\n    'level': [\"Good\", \"Moderate\", \"Unhealthy for sensitive groups\", \"Unhealthy\", \"Very unhealthy\", \"Hazardous\"]\n})\n\naqi_levels['aqi_mid'] = (aqi_levels['aqi_min'] + aqi_levels['aqi_max']) / 2\n```\n:::\n\n\n## AQI data\n\n-   Source: [EPA's Daily Air Quality Tracker](https://www.epa.gov/outdoor-air-quality-data/air-data-daily-air-quality-tracker)\n\n-   2016 - 2022 AQI (Ozone and PM2.5 combined) for Tucson, AZ core-based statistical area (CBSA), one file per year\n\n-   2016 - 2022 AQI (Ozone and PM2.5 combined) for San Francisco-Oakland-Hayward, CA CBSA, one file per year\n\n## 2022 Tucson, AZ {.smaller}\n\n::: panel-tabset\n## Read + head\n\n::: {#6b8771d2 .cell execution_count=3}\n``` {.python .cell-code}\ntuc_2022 = pd.read_csv(\"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2022.csv\")\n\ntuc_2022 = clean_columns(tuc_2022)\n\ntuc_2022.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>aqi_value</th>\n      <th>main_pollutant</th>\n      <th>site_name</th>\n      <th>site_id</th>\n      <th>source</th>\n      <th>20_year_high_2000_2019</th>\n      <th>20_year_low_2000_2019</th>\n      <th>5_year_average_2015_2019</th>\n      <th>date_of_20_year_high</th>\n      <th>date_of_20_year_low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/01/2022</td>\n      <td>40</td>\n      <td>PM2.5</td>\n      <td>GERONIMO</td>\n      <td>04-019-1113</td>\n      <td>AQS</td>\n      <td>115</td>\n      <td>35</td>\n      <td>62.2</td>\n      <td>01/01/2018</td>\n      <td>01/01/2001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/02/2022</td>\n      <td>55</td>\n      <td>PM2.5</td>\n      <td>GERONIMO</td>\n      <td>04-019-1113</td>\n      <td>AQS</td>\n      <td>57</td>\n      <td>31</td>\n      <td>43.2</td>\n      <td>01/02/2015</td>\n      <td>01/02/2016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/03/2022</td>\n      <td>55</td>\n      <td>PM2.5</td>\n      <td>GERONIMO</td>\n      <td>04-019-1113</td>\n      <td>AQS</td>\n      <td>67</td>\n      <td>29</td>\n      <td>43.6</td>\n      <td>01/03/2015</td>\n      <td>01/03/2005</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/04/2022</td>\n      <td>48</td>\n      <td>PM2.5</td>\n      <td>GERONIMO</td>\n      <td>04-019-1113</td>\n      <td>AQS</td>\n      <td>55</td>\n      <td>27</td>\n      <td>40.4</td>\n      <td>01/04/2015</td>\n      <td>01/04/2008</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/05/2022</td>\n      <td>50</td>\n      <td>PM2.5</td>\n      <td>GERONIMO</td>\n      <td>04-019-1113</td>\n      <td>AQS</td>\n      <td>52</td>\n      <td>28</td>\n      <td>36.0</td>\n      <td>01/05/2013</td>\n      <td>01/05/2000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Info\n\n::: {#393048f6 .cell execution_count=4}\n``` {.python .cell-code}\ntuc_2022.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 365 entries, 0 to 364\nData columns (total 11 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   date                      365 non-null    object \n 1   aqi_value                 365 non-null    int64  \n 2   main_pollutant            365 non-null    object \n 3   site_name                 365 non-null    object \n 4   site_id                   365 non-null    object \n 5   source                    365 non-null    object \n 6   20_year_high_2000_2019    365 non-null    int64  \n 7   20_year_low_2000_2019     365 non-null    int64  \n 8   5_year_average_2015_2019  365 non-null    float64\n 9   date_of_20_year_high      365 non-null    object \n 10  date_of_20_year_low       365 non-null    object \ndtypes: float64(1), int64(3), object(7)\nmemory usage: 31.5+ KB\n```\n:::\n:::\n\n\n## Describe\n\n::: {#e67f61b6 .cell execution_count=5}\n``` {.python .cell-code}\ntuc_2022.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aqi_value</th>\n      <th>20_year_high_2000_2019</th>\n      <th>20_year_low_2000_2019</th>\n      <th>5_year_average_2015_2019</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>365.000000</td>\n      <td>365.000000</td>\n      <td>365.000000</td>\n      <td>365.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>53.895890</td>\n      <td>83.432877</td>\n      <td>34.095890</td>\n      <td>49.835068</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>15.886967</td>\n      <td>27.515111</td>\n      <td>5.734905</td>\n      <td>10.732188</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>27.000000</td>\n      <td>44.000000</td>\n      <td>19.000000</td>\n      <td>33.800000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>44.000000</td>\n      <td>59.000000</td>\n      <td>31.000000</td>\n      <td>40.800000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>48.000000</td>\n      <td>77.000000</td>\n      <td>33.000000</td>\n      <td>47.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>61.000000</td>\n      <td>105.000000</td>\n      <td>38.000000</td>\n      <td>57.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>119.000000</td>\n      <td>161.000000</td>\n      <td>49.000000</td>\n      <td>82.400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Missing values\n\n::: {#9053f1fa .cell execution_count=6}\n``` {.python .cell-code}\ntuc_2022.isnull().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```\ndate                        0\naqi_value                   0\nmain_pollutant              0\nsite_name                   0\nsite_id                     0\nsource                      0\n20_year_high_2000_2019      0\n20_year_low_2000_2019       0\n5_year_average_2015_2019    0\ndate_of_20_year_high        0\ndate_of_20_year_low         0\ndtype: int64\n```\n:::\n:::\n\n\n:::\n\n## First look {.smaller}\n\n::: task\nThis plot looks quite bizarre. What might be going on?\n:::\n\n::: {#48f4969b .cell execution_count=7}\n``` {.python .cell-code}\nsns.lineplot(data=tuc_2022, x='date', y='aqi_value')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-8-output-1.png){width=749 height=459}\n:::\n:::\n\n\n## Transforming date {.smaller}\n\nUsing `pd.to_datetime()`:\n\n::: {#6c8c6a4a .cell execution_count=8}\n``` {.python .cell-code}\ntuc_2022['date'] = pd.to_datetime(tuc_2022['date'], format='%m/%d/%Y')\n\nprint(tuc_2022.info())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 365 entries, 0 to 364\nData columns (total 11 columns):\n #   Column                    Non-Null Count  Dtype         \n---  ------                    --------------  -----         \n 0   date                      365 non-null    datetime64[ns]\n 1   aqi_value                 365 non-null    int64         \n 2   main_pollutant            365 non-null    object        \n 3   site_name                 365 non-null    object        \n 4   site_id                   365 non-null    object        \n 5   source                    365 non-null    object        \n 6   20_year_high_2000_2019    365 non-null    int64         \n 7   20_year_low_2000_2019     365 non-null    int64         \n 8   5_year_average_2015_2019  365 non-null    float64       \n 9   date_of_20_year_high      365 non-null    object        \n 10  date_of_20_year_low       365 non-null    object        \ndtypes: datetime64[ns](1), float64(1), int64(3), object(6)\nmemory usage: 31.5+ KB\nNone\n```\n:::\n:::\n\n\n## Investigating AQI values\n\n-   Take a peek at distinct values of AQI\n\n::: {#29abb385 .cell execution_count=9}\n``` {.python .cell-code}\n# Check distinct values of aqi_value\ndistinct_aqi_values = tuc_2022['aqi_value'].unique()\nprint(distinct_aqi_values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 40  55  48  50  45  42  41  38  37  43  44  35  46  52  49  58  64  51\n  47  61  71  54  77  84  90  67  97 101  87 100  93  53  74  80 105 119\n 108  94  31  39  34  59  32  28  27  33  36  60  81]\n```\n:::\n:::\n\n\n-   `\".\"` likely indicates `NA`, and it's causing the entire column to be read in as characters\n\n## Rewind, and start over {.smaller}\n\n::: {#9271102a .cell execution_count=10}\n``` {.python .cell-code}\n# Reload data with correct NA values\ntuc_2022 = pd.read_csv(\"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2022.csv\", na_values=[\".\", \"\"])\n\n# Clean and transform data again\ntuc_2022 = clean_columns(tuc_2022)\ntuc_2022['date'] = pd.to_datetime(tuc_2022['date'], format='%m/%d/%Y')\n\n# Check the structure of the data\nprint(tuc_2022.info())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 365 entries, 0 to 364\nData columns (total 11 columns):\n #   Column                    Non-Null Count  Dtype         \n---  ------                    --------------  -----         \n 0   date                      365 non-null    datetime64[ns]\n 1   aqi_value                 365 non-null    int64         \n 2   main_pollutant            365 non-null    object        \n 3   site_name                 365 non-null    object        \n 4   site_id                   365 non-null    object        \n 5   source                    365 non-null    object        \n 6   20_year_high_2000_2019    365 non-null    int64         \n 7   20_year_low_2000_2019     365 non-null    int64         \n 8   5_year_average_2015_2019  365 non-null    float64       \n 9   date_of_20_year_high      365 non-null    object        \n 10  date_of_20_year_low       365 non-null    object        \ndtypes: datetime64[ns](1), float64(1), int64(3), object(6)\nmemory usage: 31.5+ KB\nNone\n```\n:::\n:::\n\n\n## Another look {.smaller}\n\n::: {#36815c37 .cell execution_count=11}\n``` {.python .cell-code}\nsns.lineplot(data=tuc_2022, x='date', y='aqi_value')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-12-output-1.png){width=751 height=459}\n:::\n:::\n\n\n## Visualizing Tucson AQI\n\n::: {#25dca87c .cell execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-13-output-1.png){width=753 height=527}\n:::\n:::\n\n\n## Live coding {.smaller}\n\n::: {#48d8813d .cell execution_count=13}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Setup\"}\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.dates import DateFormatter\nimport matplotlib.dates as mdates\nfrom skimpy import clean_columns\n\n# Set the theme for seaborn\nsns.set_theme(style=\"white\", palette=\"colorblind\")\n\n# Set figure parameters\nplt.rcParams['figure.figsize'] = [8, 8 * 0.618]\nplt.rcParams['figure.autolayout'] = True\naqi_levels = pd.DataFrame({\n    'aqi_min': [0, 51, 101, 151, 201, 301],\n    'aqi_max': [50, 100, 150, 200, 300, 400],\n    'color': [\"#D8EEDA\", \"#F1E7D4\", \"#F8E4D8\", \"#FEE2E1\", \"#F4E3F7\", \"#F9D0D4\"],\n    'level': [\"Good\", \"Moderate\", \"Unhealthy for sensitive groups\", \"Unhealthy\", \"Very unhealthy\", \"Hazardous\"]\n})\n\naqi_levels['aqi_mid'] = (aqi_levels['aqi_min'] + aqi_levels['aqi_max']) / 2\n\ntuc_2022 = pd.read_csv(\"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2022.csv\", na_values=[\".\", \"\"])\n\ntuc_2022 = clean_columns(tuc_2022)\ntuc_2022['date'] = pd.to_datetime(tuc_2022['date'], format='%m/%d/%Y')\n```\n:::\n\n\nReveal below for code developed during live coding session.\n\n::: {#e856281e .cell execution_count=14}\n``` {.python .cell-code code-fold=\"true\"}\n# Plot background AQI levels\nfor _, row in aqi_levels.iterrows():\n    plt.axhspan(row['aqi_min'], row['aqi_max'], color=row['color'], alpha=0.5, lw=0)\n\n# Plot AQI values\nsns.lineplot(data=tuc_2022.dropna(subset=['aqi_value']), x='date', y='aqi_value', linewidth=1.5, color=\"black\")\n\n# Annotate AQI levels\nfor _, row in aqi_levels.iterrows():\n    plt.text(pd.Timestamp('2023-02-28'), row['aqi_mid'], row['level'], ha='right', size=14, color='gray', weight='bold')\n\n# Additional annotations and formatting\nplt.annotate('2022', xy=(pd.Timestamp('2022-01-01'), -100), size=12, ha='center')\nplt.annotate('2023', xy=(pd.Timestamp('2023-03-01'), -100), size=12, ha='center')\n\nplt.xlim(pd.Timestamp('2022-01-01'), pd.Timestamp('2023-03-01'))\nplt.ylim(0, 400)\nplt.xlabel(None)\nplt.ylabel('AQI')\nplt.title('Ozone and PM2.5 Daily AQI Values\\nTucson, AZ')\nplt.figtext(0.5, -0.1, 'Source: EPA Daily Air Quality Tracker', ha='center', size=10)\nplt.gca().xaxis.set_major_formatter(DateFormatter('%b'))\nplt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n\nplt.show()\n```\n:::\n\n\n# Calculating cumulatives\n\n## Cumulatives over time\n\n-   When visualizing time series data, a somewhat common task is to calculate cumulatives over time and plot them\n\n-   In our example we'll calculate the number of days with \"good\" AQI ($\\le$ 50) and plot that value on the y-axis and the date on the x-axis\n\n## Calculating cumulatives\n\nStep 1. Arrange your data\n\n::: {#f4004700 .cell execution_count=15}\n``` {.python .cell-code}\ntuc_2022 = tuc_2022[['date', 'aqi_value']].dropna().sort_values('date')\n```\n:::\n\n\n## Calculating cumulatives\n\nStep 2. Identify good days\n\n::: {#3541feed .cell execution_count=16}\n``` {.python .cell-code}\ntuc_2022['good_aqi'] = np.where(tuc_2022['aqi_value'] <= 50, 1, 0)\n```\n:::\n\n\n## Calculating cumulatives\n\nStep 3. Sum over time\n\n::: {#4615e469 .cell execution_count=17}\n``` {.python .cell-code}\ntuc_2022['cumsum_good_aqi'] = tuc_2022['good_aqi'].cumsum()\n```\n:::\n\n\n## Plotting cumulatives {.smaller}\n\n::: panel-tabset\n### Plot\n\n::: {#ed7893af .cell fig.asp='0.5' execution_count=18}\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-19-output-1.png){width=749 height=527}\n:::\n:::\n\n\n### Code\n\n::: {#cd1d7026 .cell execution_count=19}\n``` {.python .cell-code}\nsns.lineplot(data=tuc_2022, x='date', y='cumsum_good_aqi')\nplt.gca().xaxis.set_major_formatter(DateFormatter(\"%b %Y\"))\n\nplt.xlabel(None)\nplt.ylabel(\"Number of days\")\nplt.title(\"Cumulative number of good AQI days (AQI < 50)\\nTucson, AZ\")\nplt.figtext(0.5, -0.1, 'Source: EPA Daily Air Quality Tracker', ha='center', size=10)\n\nplt.show()\n```\n:::\n\n\n:::\n\n# Detrending\n\n## Detrending\n\n-   Detrending is removing prominent long-term trend in time series to specifically highlight any notable deviations\n\n-   Let's demonstrate using multiple years of AQI data\n\n## Multiple years of Tucson, AZ data {.smaller}\n\n\n## Reading multiple files {.smaller}\n\n::: {#e970fb21 .cell message='false' execution_count=21}\n``` {.python .cell-code}\n# Define the list of URLs\ntuc_files = [\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2022.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2021.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2020.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2019.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2018.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/tucson/ad_aqi_tracker_data-2017.csv\"\n]\n\n# Initialize an empty dataframe\ntuc = pd.DataFrame()\n\n# Read and concatenate all data files\nfor file in tuc_files:\n    data = pd.read_csv(file, na_values=[\".\", \"\"])\n    tuc = pd.concat([tuc, data], ignore_index=True)\n\n# Clean column names using the clean_columns function from the skimpy package\ntuc = clean_columns(tuc)\n\n# Clean and transform data\ntuc['date'] = pd.to_datetime(tuc['date'], format='%m/%d/%Y')\ntuc = tuc.dropna(subset=['aqi_value'])\ntuc['good_aqi'] = np.where(tuc['aqi_value'] <= 50, 1, 0)\ntuc = tuc.sort_values('date')\ntuc['cumsum_good_aqi'] = tuc['good_aqi'].cumsum()\n\n# Convert date to ordinal for regression\ntuc['date_ordinal'] = tuc['date'].apply(lambda x: x.toordinal())\n\nprint(tuc.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           date  aqi_value main_pollutant     site_name      site_id source  \\\n1826 2017-01-01         38          Ozone  SAGUARO PARK  04-019-0021    AQS   \n1827 2017-01-02         40          Ozone  SAGUARO PARK  04-019-0021    AQS   \n1828 2017-01-03         38          Ozone  SAGUARO PARK  04-019-0021    AQS   \n1829 2017-01-04         38          Ozone  SAGUARO PARK  04-019-0021    AQS   \n1830 2017-01-05         32          Ozone  SAGUARO PARK  04-019-0021    AQS   \n\n      20_year_high_2000_2019  20_year_low_2000_2019  5_year_average_2015_2019  \\\n1826                     115                     35                      62.2   \n1827                      57                     31                      43.2   \n1828                      67                     29                      43.6   \n1829                      55                     27                      40.4   \n1830                      52                     28                      36.0   \n\n     date_of_20_year_high date_of_20_year_low  good_aqi  cumsum_good_aqi  \\\n1826           01/01/2018          01/01/2001         1                1   \n1827           01/02/2015          01/02/2016         1                2   \n1828           01/03/2015          01/03/2005         1                3   \n1829           01/04/2015          01/04/2008         1                4   \n1830           01/05/2013          01/05/2000         1                5   \n\n      date_ordinal  \n1826        736330  \n1827        736331  \n1828        736332  \n1829        736333  \n1830        736334  \n```\n:::\n:::\n\n\n## Simple Linear Regression\n\n::: {#db1257b0 .cell execution_count=22}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\n\n# Fit linear regression for the trend line\nmodel = LinearRegression()\nmodel.fit(tuc[['date_ordinal']], tuc['cumsum_good_aqi'])\ntuc['fitted'] = model.predict(tuc[['date_ordinal']])\n```\n:::\n\n\n## Plot trend since 2017 {.smaller}\n\n::: panel-tabset\n### Plot\n\n::: {#cell-tuc-3 .cell fig-asp='0.5' execution_count=23}\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/tuc-3-output-1.png){#tuc-3 width=753 height=527}\n:::\n:::\n\n\n### Code\n\n::: {#be15cb6f .cell execution_count=24}\n``` {.python .cell-code}\nsns.lineplot(data=tuc, x='date', y='cumsum_good_aqi', color = 'black')\nsns.lineplot(data=tuc, x='date', y='fitted', color='pink', label='Trend Line')\n\nplt.gca().xaxis.set_major_formatter(DateFormatter(\"%Y\"))\nplt.xlabel(None)\nplt.ylabel(\"Number of days\")\nplt.title(\"Cumulative number of good AQI days (AQI < 50)\\nTucson, AZ\")\nplt.figtext(0.5, -0.1, 'Source: EPA Daily Air Quality Tracker', ha='center', size=10)\nplt.show()\n```\n:::\n\n\n:::\n\n## Detrend\n\nStep 1. Fit a simple linear regression\n\n::: {#ff719f79 .cell execution_count=25}\n``` {.python .cell-code}\n# Convert dates to ordinal for regression\ntuc['date_ordinal'] = tuc['date'].apply(lambda x: x.toordinal())\n\n# Fit linear regression\nmodel = LinearRegression()\nmodel.fit(tuc[['date_ordinal']], tuc['cumsum_good_aqi'])\n\n# Get fitted values\ntuc['fitted'] = model.predict(tuc[['date_ordinal']])\n```\n:::\n\n\n## Detrend\n\nStep 2. Divide the observed value of `cumsum_good_aqi` by the respective value in the long-term trend (i.e., `fitted`)\n\n::: {#87420f2a .cell execution_count=26}\n``` {.python .cell-code}\ntuc['ratio'] = tuc['cumsum_good_aqi'] / tuc['fitted']\n```\n:::\n\n\n## Visualize detrended data {.smaller}\n\n::: panel-tabset\n### Plot\n\n::: {#cell-tuc-4 .cell fig-asp='0.5' execution_count=27}\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/tuc-4-output-1.png){#tuc-4 width=753 height=527}\n:::\n:::\n\n\n### Code\n\n::: {#d75631ba .cell execution_count=28}\n``` {.python .cell-code}\nplt.axhline(y=1, color='gray')\nsns.lineplot(data=tuc, x='date', y='ratio', color='black')\nplt.gca().xaxis.set_major_formatter(DateFormatter(\"%Y\"))\nplt.ylim([0, 20])\nplt.xlabel(None)\nplt.ylabel(\"Number of days\\n(detrended)\")\nplt.title(\"Cumulative number of good AQI days (AQI < 50)\\nTucson, AZ (2016-2022)\")\nplt.figtext(0.5, -0.1, 'Source: EPA Daily Air Quality Tracker', ha='center', size=10)\nplt.show()\n```\n:::\n\n\n:::\n\n## Air Quality in Tucson\n\n<br><br>\n\n::: hand\nbarely anything interesting happening!\n:::\n\n. . .\n\n::: hand\nlet's look at data from somewhere with a bit more \"interesting\" air quality data...\n:::\n\n## Read in multiple years of SF data {.smaller}\n\n::: {#7157cf46 .cell execution_count=29}\n``` {.python .cell-code code-fold=\"true\"}\n# Define the list of URLs\nsf_files = [\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2022.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2021.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2020.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2019.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2018.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2017.csv\",\n    \"https://raw.githubusercontent.com/Gchism94/GL-dataviz-lectures/main/slides/data/san-francisco/ad_aqi_tracker_data-2016.csv\"\n]\n\n# Initialize an empty dataframe\nsf = pd.DataFrame()\n\n# Read and concatenate all data files\nfor file in sf_files:\n    data = pd.read_csv(file, na_values=[\".\", \"\"])\n    sf = pd.concat([sf, data], ignore_index=True)\n\n# Clean column names using the clean_columns function from the skimpy package\nsf = clean_columns(sf)\n\n# Clean and transform data\nsf['date'] = pd.to_datetime(sf['date'], format='%m/%d/%Y')\nsf = sf.dropna(subset=['aqi_value'])\nsf['good_aqi'] = np.where(sf['aqi_value'] <= 50, 1, 0)\nsf = sf.sort_values('date')\nsf['cumsum_good_aqi'] = sf['good_aqi'].cumsum()\n\n# Convert date to ordinal for regression\nsf['date_ordinal'] = sf['date'].apply(lambda x: x.toordinal())\n\nprint(sf.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           date  aqi_value main_pollutant      site_name      site_id source  \\\n2191 2016-01-01         32          PM2.5  Durham Armory  37-063-0015    AQS   \n2192 2016-01-02         37          PM2.5  Durham Armory  37-063-0015    AQS   \n2193 2016-01-03         45          PM2.5  Durham Armory  37-063-0015    AQS   \n2194 2016-01-04         33          PM2.5  Durham Armory  37-063-0015    AQS   \n2195 2016-01-05         27          PM2.5  Durham Armory  37-063-0015    AQS   \n\n      20_year_high_2000_2019  20_year_low_2000_2019  5_year_average_2015_2019  \\\n2191                     111                     10                      39.2   \n2192                      76                      8                      36.8   \n2193                      66                     14                      38.2   \n2194                      61                      9                      30.4   \n2195                      83                      8                      26.0   \n\n     date_of_20_year_high date_of_20_year_low  good_aqi  cumsum_good_aqi  \\\n2191           01/01/2000          01/01/2007         1                1   \n2192           01/02/2005          01/02/2012         1                2   \n2193           01/03/2004          01/03/2012         1                3   \n2194           01/04/2008          01/04/2007         1                4   \n2195           01/05/2001          01/05/2015         1                5   \n\n      date_ordinal  \n2191        735964  \n2192        735965  \n2193        735966  \n2194        735967  \n2195        735968  \n```\n:::\n:::\n\n\n## Simple Linear Regression\n\n::: {#09887381 .cell execution_count=30}\n``` {.python .cell-code}\n# Fit linear regression for the trend line\nmodel = LinearRegression()\nmodel.fit(sf[['date_ordinal']], sf['cumsum_good_aqi'])\nsf['fitted'] = model.predict(sf[['date_ordinal']])\n```\n:::\n\n\n## Plot trend since 2016 {.smaller}\n\n::: panel-tabset\n### Plot\n\n::: {#cell-sf-1 .cell fig-asp='0.5' execution_count=31}\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/sf-1-output-1.png){#sf-1 width=753 height=527}\n:::\n:::\n\n\n### Code\n\n::: {#07d6e805 .cell execution_count=32}\n``` {.python .cell-code}\nsns.lineplot(data=sf, x='date', y='cumsum_good_aqi', color = 'black')\nsns.lineplot(data=sf, x='date', y='fitted', color='pink', label='Trend Line')\n\nplt.gca().xaxis.set_major_formatter(DateFormatter(\"%Y\"))\nplt.xlabel(None)\nplt.ylabel(\"Number of days\")\nplt.title(\"Cumulative number of good AQI days (AQI < 50)\\nSan Francisco, CA\")\nplt.figtext(0.5, -0.1, 'Source: EPA Daily Air Quality Tracker', ha='center', size=10)\nplt.show()\n```\n:::\n\n\n:::\n\n## Detrend\n\nStep 1. Fit a simple linear regression\n\n::: {#acc706c8 .cell execution_count=33}\n``` {.python .cell-code}\n# Convert dates to ordinal for regression\nsf['date_ordinal'] = sf['date'].apply(lambda x: x.toordinal())\n\n# Fit linear regression\nmodel = LinearRegression()\nmodel.fit(sf[['date_ordinal']], sf['cumsum_good_aqi'])\n\n# Get fitted values\nsf['fitted'] = model.predict(sf[['date_ordinal']])\n```\n:::\n\n\n## Detrend\n\nStep 2. Divide the observed value of `cumsum_good_aqi` by the respective value in the long-term trend (i.e., `fitted`)\n\n::: {#a069e00c .cell execution_count=34}\n``` {.python .cell-code}\nsf['ratio'] = sf['cumsum_good_aqi'] / sf['fitted']\n```\n:::\n\n\n## Visualize detrended data {.smaller}\n\n::: panel-tabset\n### Plot\n\n::: {#cell-sf-2 .cell fig-asp='0.5' execution_count=35}\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/sf-2-output-1.png){#sf-2 width=753 height=527}\n:::\n:::\n\n\n### Code\n\n::: {#7cc0f607 .cell execution_count=36}\n``` {.python .cell-code}\nplt.axhline(y=1, color='gray')\nsns.lineplot(data=sf, x='date', y='ratio', color='black')\nplt.gca().xaxis.set_major_formatter(DateFormatter(\"%Y\"))\nplt.xlabel(None)\nplt.ylabel(\"Number of days\\n(detrended)\")\nplt.title(\"Cumulative number of good AQI days (AQI < 50)\\nSan Francisco, CA (2016-2022)\")\nplt.figtext(0.5, -0.1, 'Source: EPA Daily Air Quality Tracker', ha='center', size=10)\nplt.show()\n```\n:::\n\n\n:::\n\n## Detrending\n\n-   In step 2 we fit a very simple model\n\n-   Depending on the complexity you're trying to capture you might choose to fit a much more complex model\n\n-   You can also decompose the trend into multiple trends, e.g. monthly, long-term, seasonal, etc.\n\n# Highlighting\n\n## Data prep {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {#211997de .cell execution_count=37}\n``` {.python .cell-code}\nfrom datetime import datetime\n\nsf['year'] = sf['date'].dt.year\nsf['day_of_year'] = sf['date'].dt.dayofyear\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#7c0666e2 .cell execution_count=38}\n``` {.python .cell-code}\n# check\nprint(sf[sf['day_of_year'] < 3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           date  aqi_value main_pollutant              site_name      site_id  \\\n2191 2016-01-01         32          PM2.5          Durham Armory  37-063-0015   \n2192 2016-01-02         37          PM2.5          Durham Armory  37-063-0015   \n1826 2017-01-01         55          PM2.5              San Pablo  06-013-1004   \n1827 2017-01-02         36          Ozone         Patterson Pass  06-001-2005   \n1461 2018-01-01         87          PM2.5           Oakland West  06-001-0011   \n1462 2018-01-02         95          PM2.5           Oakland West  06-001-0011   \n1096 2019-01-01         33          PM2.5           Redwood City  06-081-1001   \n1097 2019-01-02         50          PM2.5              Livermore  06-001-0007   \n730  2020-01-01         53          PM2.5                Oakland  06-001-0009   \n731  2020-01-02         43          PM2.5  Berkeley Aquatic Park  06-001-0013   \n365  2021-01-01         79          PM2.5           Oakland West  06-001-0011   \n366  2021-01-02         57          PM2.5  Pleasanton - Owens Ct  06-001-0015   \n0    2022-01-01         53          PM2.5                Oakland  06-001-0009   \n1    2022-01-02         55          PM2.5              Livermore  06-001-0007   \n\n     source  20_year_high_2000_2019  20_year_low_2000_2019  \\\n2191    AQS                     111                     10   \n2192    AQS                      76                      8   \n1826    AQS                     162                     33   \n1827    AQS                     140                     21   \n1461    AQS                     162                     33   \n1462    AQS                     140                     21   \n1096    AQS                     162                     33   \n1097    AQS                     140                     21   \n730     AQS                     162                     33   \n731     AQS                     140                     21   \n365     AQS                     162                     33   \n366     AQS                     140                     21   \n0       AQS                     162                     33   \n1       AQS                     140                     21   \n\n      5_year_average_2015_2019 date_of_20_year_high date_of_20_year_low  \\\n2191                      39.2           01/01/2000          01/01/2007   \n2192                      36.8           01/02/2005          01/02/2012   \n1826                      60.6           01/01/2001          01/01/2019   \n1827                      63.2           01/02/2001          01/02/2002   \n1461                      60.6           01/01/2001          01/01/2019   \n1462                      63.2           01/02/2001          01/02/2002   \n1096                      60.6           01/01/2001          01/01/2019   \n1097                      63.2           01/02/2001          01/02/2002   \n730                       60.6           01/01/2001          01/01/2019   \n731                       63.2           01/02/2001          01/02/2002   \n365                       60.6           01/01/2001          01/01/2019   \n366                       63.2           01/02/2001          01/02/2002   \n0                         60.6           01/01/2001          01/01/2019   \n1                         63.2           01/02/2001          01/02/2002   \n\n      good_aqi  cumsum_good_aqi  date_ordinal       fitted     ratio  year  \\\n2191         1                1        735964    22.288160  0.044867  2016   \n2192         1                2        735965    22.861827  0.087482  2016   \n1826         0              267        736330   232.250591  1.149620  2017   \n1827         1              268        736331   232.824259  1.151083  2017   \n1461         0              440        736695   441.639355  0.996288  2018   \n1462         0              440        736696   442.213023  0.994996  2018   \n1096         1              589        737060   651.028119  0.904723  2019   \n1097         1              590        737061   651.601787  0.905461  2019   \n730          0              843        737425   860.416883  0.979758  2020   \n731          1              844        737426   860.990550  0.980266  2020   \n365          0             1070        737791  1070.379314  0.999646  2021   \n366          0             1070        737792  1070.952982  0.999110  2021   \n0            0             1282        738156  1279.768078  1.001744  2022   \n1            0             1282        738157  1280.341746  1.001295  2022   \n\n      day_of_year  \n2191            1  \n2192            2  \n1826            1  \n1827            2  \n1461            1  \n1462            2  \n1096            1  \n1097            2  \n730             1  \n731             2  \n365             1  \n366             2  \n0               1  \n1               2  \n```\n:::\n:::\n\n\n:::\n:::\n\n## Plot AQI over years {.smaller}\n\n::: {#dbb7f49f .cell execution_count=39}\n``` {.python .cell-code}\nsns.lineplot(data=sf, x='day_of_year', y='aqi_value', hue='year', palette='tab10', legend=False)\nplt.xlabel('Day of year')\nplt.ylabel('AQI value')\nplt.title('AQI levels in San Francisco (2016 - 2022)')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-40-output-1.png){width=753 height=459}\n:::\n:::\n\n\n## Highlight specific year (2016) {.smaller}\n\n::: {#407f3dd7 .cell execution_count=40}\n``` {.python .cell-code code-fold=\"true\"}\n# Highlight the year 2016\nsns.lineplot(data=sf, x='day_of_year', y='aqi_value', color='gray')\nsns.lineplot(data=sf[sf['year'] == 2016], x='day_of_year', y='aqi_value', color='red')\nplt.xlabel('Day of year')\nplt.ylabel('AQI value')\nplt.title('AQI levels in SF in 2016\\nVersus all years 2016 - 2022')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-41-output-1.png){width=753 height=459}\n:::\n:::\n\n\n## Highlight specific year (2017) {.smaller}\n\n::: {#e0448d21 .cell execution_count=41}\n``` {.python .cell-code code-fold=\"true\"}\n# Highlight the year 2017\nsns.lineplot(data=sf, x='day_of_year', y='aqi_value', color='gray')\nsns.lineplot(data=sf[sf['year'] == 2017], x='day_of_year', y='aqi_value', color='red')\nplt.xlabel('Day of year')\nplt.ylabel('AQI value')\nplt.title('AQI levels in SF in 2017\\nVersus all years 2016 - 2022')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-42-output-1.png){width=753 height=459}\n:::\n:::\n\n\n## Highlight specific year (2018) {.smaller}\n\n::: {#d9942b78 .cell execution_count=42}\n``` {.python .cell-code code-fold=\"true\"}\n# Highlight the year 2018\nsns.lineplot(data=sf, x='day_of_year', y='aqi_value', color='gray')\nsns.lineplot(data=sf[sf['year'] == 2018], x='day_of_year', y='aqi_value', color='red')\nplt.xlabel('Day of year')\nplt.ylabel('AQI value')\nplt.title('AQI levels in SF in 2018\\nVersus all years 2016 - 2022')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-43-output-1.png){width=753 height=459}\n:::\n:::\n\n\n## Highlight any year {.smaller}\n\n::: {#040d221d .cell execution_count=43}\n``` {.python .cell-code code-fold=\"true\"}\n# Function to highlight a specific year\ndef highlight_year(year_to_highlight):\n    sns.lineplot(data=sf, x='day_of_year', y='aqi_value', color='gray')\n    sns.lineplot(data=sf[sf['year'] == year_to_highlight], x='day_of_year', y='aqi_value', color='red')\n    plt.xlabel('Day of year')\n    plt.ylabel('AQI value')\n    plt.title(f'AQI levels in SF in {year_to_highlight}\\nVersus all years 2016 - 2022')\n    plt.show()\n\n# Highlight any year\nhighlight_year(2018)\n```\n\n::: {.cell-output .cell-output-display}\n![](week4_files/figure-revealjs/cell-44-output-1.png){width=753 height=459}\n:::\n:::\n\n\n# Thank you 😊\n\n",
    "supporting": [
      "week4_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}